
# 基础设置

- %ComfyUI_path%/ComfyUI/models : 所有的模型
- %ComfyUI_path/ComfyUI/custom_nodes: 所有的插件,直接git clone

## 基础节点以及工作流
### K-采样器

新建节点 -> 采样 -> K-采样器 创建新采样器

据说不同采样器之间其实没什么差别

![](../../../../../assets/other/ComfyUI/k-sampler.png)

- 种子: 随机数种子
- 步数: 生成步数
- 调度器: 在SD中采样器与调度器是结合显示

e.g.SD中采样方法DPM++2M Karras在ComfyUI中则需要选择采样器：DPM++2M；调度器Karras。两者分开选取

#### 采样器:

如果只是想要普通生成一张图片,大部分默认采用euler_ancestral采样器+normal调度器的组合

如果想要提高图片质量,通常会使用DPM++采样器,但对于提升图片质量 DPM++2M不如带sde后缀的采样器

sde增加了图像的发挥性和想象力,对于生成的图像会有更多的变化,吹按更多惊喜

DPM采样器分为两种,一种带GPU调用GPU,一种不用GPU,

ICM采样器通常配合实时绘画工作流使用

Uni PC类似ICM,可以在10步以内出不错的图像

#### 调度器:

- normal: 平均降噪(线性降噪)
- karras: s型降噪,比较常用
- exponential: 断崖式下降
- sgm_uniform: 定向性降噪,需要配合ICM

#### 降噪幅度:
一般根据部署决定

### 完整工作流:
#### CLIP文本:
用于输入关键字,可以正面负面分别传入

### 分组:
条件过多的时候可以邮件新建分组,或者shift选中节点ctrl+G

# SD:

把图片进行压缩,像素空间变到潜在空间,在潜在空间扩散,之后在转换成像素空间

## Latent 说明:

- 如果需要进行空间转换需要Latent节点,可以配置图像宽度,高度和批次
- 采样器, Checkpoint加载器,latent, 模型传递的参数处于潜在空间
- 如果在K-采样器之后在连接一个K-采样器可以二次采样
- 如果需要从潜在空间变回正常图片需要把采样器的Latent连接到VAE解码,最后的VAE需要链接到Checkpoint模型加载器上的VAE

## VAE 解码说明:
如果模型没有VAE或者特定挂载了一些VAE,需要冲洗脱出一个VAE加载器,单独读取一个VAE模型

然后可以连接一个保存图像节点

### CLIP文本说明:

CLIP的原理是把文字编码,转化成不是纯文本,所以不能把纯文字节点连接到采样器上,

# 底层逻辑:

## 图生图逻辑:

我们可以把之前的latent图像变成一个指定图像,用指定的图像去采样生成新图像,所以要把图像传到浅空间

图像是知识的像素,遮罩输出一般不用管,是黑白蒙版的输出

由于要传到浅空间,所以要裹一层VAE编码到潜在空间

图生图中的建造等于SD中的重绘幅度

通常来说在解决了空间问题以后,很容易的就可以实现图生图的简单功能


# 节点技巧/多模型并联
## Alek节点组(感觉不算太必要?)
主要是文本翻译

- CLIP(Argos翻译): 指定翻译的语言
- CLIP(翻译高级): 指定语言和翻译引擎以及翻译接口

和weilin一样,联机CLIP的text部分(默认会隐藏为文本框,需要拖动到那上面才会显示)

## 提升变量:

比如说有两个k采样器,两组生成内容不一样,但其他设置相同,就可以把这部分提取出来

选中k采样器,然后转换随机种为输入,就会多一个随机种子的节点,输入需要用源节点(primitive)

这样可以一个源节点链接两个k采样器

## 提词技巧:

在ComfyUI custom function 里有个字符串操作

输入多个字符串,如果是替换就会变成第一个,拼接就会都拼一起

也可以向上面那样创建一堆元节点,然后连到字符串操作上

### 自定义变量:

可以点击自定义语句,读取本身的txt文件,有力custom nodes之后输入会弹出一些常用的词汇

## 查看模型信息:

包括主模型,可以邮件查看信息,直接读取civitiai的模型数据内容

## 吸附网络:

点击左上角圆圈的左下角可以折叠节点

# 多模型并联:
## lora:

不断加lora节点,和模型形成一个管道,但还是更喜欢lora堆一点

## CLIP 停止层

lora的过程大致如下:

- 主模型信息经过lora
- 主模型CLIP经过lora
- 处理完把lora的CLIP传给文本
- 文本调整之后直接给到采样器
- lora处理外的模型给到采样器

CLIP跳过层:

默认是-1,如果出动漫效果就填-2

## inpaint:

重绘:

在ComfyUI里可以对浅空间进行修改,不需要编码,可以自由转换

并且由于同处浅空间,多次生成后的图片和之前的原图混合度会更好
### 浅空间之外

需要一个加载图像,(没办法直接把编码的图像加载过来,需要用插件)

然后过一遍VAE变到潜在空间, 之后绘制遮罩

#### VAE内部编码器:

遮罩部分的编码,会识别遮罩,比VAE多了一个遮罩信息点

经过内补编码器之后再传进K采样器里

### 提词对应场景:

这部分的题词应该是遮罩部分的内容,不是整张图像的图

### 潜在空间之外:

先设置一个遮罩,然后设置latent噪波采样,堆遮罩的部分二次采样

建议第二次以及第三次重绘至少1024的分辨率,对于姿势给到的降噪幅度过高,在腿和鞋的处理会很怪异
