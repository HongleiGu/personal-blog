---
encrypt_content:
  level: Imperial
  password: Raymond#1234
  username: hg1523
level: Imperial
---

we want to minimise the number of registers needed - and therefore avoids spilling intermediate values into main store whenever possible

Effective use of registers is vital since access to registers is much faster than access to main memory because
- registers need expensive fast circuitry, it is ok in small quantities if used well
- Registers are multi-ported: two or more registers can be read in the same clock cycle
- Registers are specified by a small field in the instruction

# Avoid running out of registers

## the idea: Order does matter

example $x + (3 + (y*2))$

Using straightforward code generator yield:

```
LoadAbs R0 "x"
LoadImm R1 3,
LoadAbs R2 "y"
LoadImm R3 2,
Mul R2 R3
Add R1 R2,
Add R0 R1
```

to modify the expression to $((y*2) + 3) + x$

```
LoadAbs R0 "y"
LoadImm R1 2,
Mul R0 R1,
LoadImm R1 3,
Add R0 R1,
LoadAbs R1 "x"
Add R0 R1
```

so we reduced the number of registers used from 4 to 2

## Subexpression ordering principle:

Given an expression e1 op e2, always choose to evaluate first the expression which will require more registers:

because
- During evaluation of the second subexpression, one register will be used up holding the results of evaluating the first expression.
- So there is one more register free during evaluation of the first subexpression

## Putting this principle to work:

- Consider binary operator application e1 op e2
- Suppose e1 requires L registers and e2 requires R registers
- If e1 is evaluated first, we will need L registers to evaluate e1 and R registers to evaluate e2 PLUS one to hold the result of e1
- If e1 is evaluated first the maximum number of registers in use at once if $max(L, R+1)$
- If e2 is evaluated first the maximum number of registers in use at once if $max(L+1, R)$
- we choose the order which yields the smaller value
Suppose we had a function weight which calculates how many registers will  be needed to evaluate each subexpression. We could use this to decide which subexpression to evaluate first

```haskell
weight :: Exp -> Int
weight (Const n) = 1
weight (Ident x) = 1

weight (Binop op e1 e2)
	= min cost1 cost2
	where
		-- if we choose to do e1 first
		cost1 = max (weight e1, weight e2 + 1)
		-- if we choose to do e2 first
		cost2 = max (weight e1 + 1, weight e2)
```

when the subexpressions have the same weight, neither is better - it doesnt matter

this weight

## Modifications to the code generator

we want the subexpressions to be evaluated based on the weights

```haskell
transExp (Binop op e1 e2) r
	=   if weight e1 > weight e1
		then
			transExp e1 r ++
			transExp e2 (r+1) ++
			transBinop op r (r+1)
		else
			transExp e2 r ++
			transExp e1 (r+1) ++
			transBinop op r (r+1)
```

this is OK only if the operator is commutative

the problem with this is that the code generated by `transExp e1 r` might clobber the value in register r+1

## Register Targeting

- Problem: We want to be able to tell `transExp` to leave the result in register r but it cannot use register r+1
- Idea: give transExp a list of registers it is allowed to use

```haskell
transExp :: Exp -> [Register] -> [Instruction]
```

The translator transExp is given a list of the registers it is allowed to use. It should leave the result in the first register in the list

The base cases:

```haskell
transExp (Const n) (destReg:restOfRegs)
 = [LoadImm destReg n]
transExp (Ident x) (destReg:restOfRegs)
 = [LoadAbs destreg x]
```

binary operator:

```haskell
transExp (Binop op e1 e2) (dstReg:nxtReg:regs)
 =  if weight e1 > weight e2 then
		transExp e1 (dstReg:nxtReg:regs) ++
		-- e1 can use all regs
		transExp e2 (nxtReg:regs) ++
		-- e2 can use all but one
		transBinop op dstReg nxtReg
		-- e1 & e2 still delivered to right registers
	else
		transExp e2 (nxtReg:dstReg:regs) ++
		-- e2 can use all regs
		transExp e1 (dstReg:regs) ++
		-- e1 can use all but one
		transBinop op dstReg nxtReg
		-- e1 & e2 still delivered to right registers
```

The arithmetic instruciton ends up the same either way - because the operands are in the same place, whichever order we choose

for example

![lecture5-part1-slide10](lecture5-part1-slide10.png)

## Embellishment: immediate operands

As we saw before, it is important to use immediate addressing modes wherever possible i.e.
```
LoadImm R1 100, (eg. movl $100, %ebx)
Mul R0 R1       (eg. imull %ebx, %eax)
```

Can be improved using immediate addressing
```
MulImm R0 100    (eg. imull $100, %eax)
```
The translator can use pattern-matching to catch opportunities to do this

The weight function must be modified so that it correctly predicts how many registers will be used


## Effectiveness of Sethi-Ullman numbering

identify worst case:
- perfectly balanced expression tree (since an unbalance tree can always be evaluated in an order which reduces register demand)
- k values
- $\frac{k}{2} - 1$ operators
- $\lceil\log_2 k\rceil$

So the expression size accommodated using a block of N registers is proportional to $2^N$

# Register-Allocation: Summary

- Sethi-Ullman numbering minimises register usage in arithmetic expression evalution
- It works by choosing subexpression evaluation order: do register-hungry subexpressions first because later registers will be occupied by the results of earlier evaluations
- Sethi-Ullman numbering is optimal in a very restricted sense: it fails to handle reused variables and it fails to put user variables in register
- However it is fast, reliable and reasonably effective (e.g was used in C compilers for may years)
- Optimising compiles commonly use more sophisticated techniques, for example based on graph colouring

